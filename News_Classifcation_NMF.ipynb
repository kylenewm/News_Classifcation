{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "6geCR5Xo_uqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the length of the original notebook, I decided to create a separate submission for the Non-Negative Matrix Factroization."
      ],
      "metadata": {
        "id": "DVXiGKAdLTws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An **important distinction** to make is the differnce between topic modeling and topic classification. Topic modeling groups unlabeld text by the topics the model thinks it contains and groups them by those topics. Topic classification  contains labeled training data. Hence with topic modeling we generally deal with unsupervised techniques such as Latent Dirichlet Allocation and Latent Semantic Analysis. While with topic classification we generally deal with supervised learning algorithms such as support vector machines and naive bayes analysis. There are also deep learning architectures used for text classification auch as Convolutional Neural Networks and Recurrent Neural Networks. I will provide resources in a separate notebook for further information. "
      ],
      "metadata": {
        "id": "HzEdPmVpLQ9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "\n",
        "**Issue with NMF for classifcation** : Nonnegative matrix factorization is often utlized for topic modeling and not top classifcation. For topic modeling, we can choose a certain number of topics for the matrix to be contained in. For our purposes, we will choose 5 topics (since we have 5 different catgeories to classify articles). "
      ],
      "metadata": {
        "id": "isR5mM2z9RFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** This notebook is for learning purposes. It is **not** an attempt to achieve better results or runtime than the supervised models used in the other notebook. "
      ],
      "metadata": {
        "id": "L5GD1M3IUrnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Dependencies"
      ],
      "metadata": {
        "id": "pB9fjmVS_r6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets # for downloading dataset into notenook with Kaggle API key\n",
        "!pip install NLTK #installing NLTK and packages needed for preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmjXr3mn_WrX",
        "outputId": "1364cb0b-5898-4d5d-af3c-4a996bfd5697"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.7/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.9.24)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from NLTK) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from NLTK) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from NLTK) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from NLTK) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Modules"
      ],
      "metadata": {
        "id": "IW34BqJi_kKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import sklearn.metrics as metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from itertools import permutations"
      ],
      "metadata": {
        "id": "14A7r3iH9EM_"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Required Downloads from NLTK for preprocessing"
      ],
      "metadata": {
        "id": "RyJm_6_O_dUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "499WGeem9Fdh",
        "outputId": "5d5f48f5-7167-49c5-851d-c105d76e0557"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/competitions/learn-ai-bbc/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjNXjf-_9HPZ",
        "outputId": "7b09297f-2597-45f5-87b7-a9e44608039d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./learn-ai-bbc\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/learn-ai-bbc/BBC News Test.csv', low_memory = False) \n",
        "train =  pd.read_csv('/content/learn-ai-bbc/BBC News Train.csv', low_memory = False)"
      ],
      "metadata": {
        "id": "FDfbpIiW9KFM"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Condensed Preprocessing and Vectorizing"
      ],
      "metadata": {
        "id": "Nibkbrgh_9Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(df,col_text):\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  stop_words.add('said') #appending 'said' to stop_words list\n",
        "  for i in range(len(df[col_text])):\n",
        "    df[col_text][i] = word_tokenize(df[col_text][i]) #tokenizing\n",
        "  for i in range(len(df)):\n",
        "    df[col_text][i] = [word for word in df[col_text][i] if word not in string.punctuation] #removing punctuation \n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  for i in range(len(df)):\n",
        "    df[col_text][i] = [word for word in df[col_text][i] if word not in stop_words] #removing stopwords\n",
        "  for i in range(len(df)):\n",
        "    df[col_text][i] = [lemmatizer.lemmatize(word) for word in df[col_text][i]] #lemmatizing\n",
        "  for i in range(len(df)):\n",
        "    df[col_text][i] = ' '.join(df[col_text][i]) #rejoining words within each row to allow for vectorization \n",
        "  return df"
      ],
      "metadata": {
        "id": "5Q6p2Zq59nol"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessing(train, 'Text') #preprocessing text for model\n",
        "train_vec = TfidfVectorizer().fit_transform(train['Text'].values) #vectorizing for model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMY3vWXP9qvq",
        "outputId": "6e29047b-0f9e-44e4-e850-9e51c000fa38"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "u73adGAeAITQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "LI-0bjsu8vLH"
      },
      "outputs": [],
      "source": [
        "nmf = NMF(n_components=5, \n",
        "                init='nndsvda', \n",
        "                solver = 'mu',\n",
        "                beta_loss = 'kullback-leibler',\n",
        "                l1_ratio = 0.5,\n",
        "                random_state = 47)\n",
        "transformed = nmf.fit_transform(train_vec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_topics = [np.argsort(each)[::-1][0] for each in transformed]"
      ],
      "metadata": {
        "id": "l-Qs9v3L8-2f"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_topics[0:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfRWfx4KBhxB",
        "outputId": "648f3d1d-f55b-4bcd-a739-72e9635ec43f"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 4, 4, 2, 4, 1, 0, 3, 4, 3, 1, 3, 4, 4, 0, 0, 3, 0, 0, 2, 0, 3, 0, 0, 2, 4, 2, 0, 1, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_max_accuracy(df, true_val_col, pred_labels): #takes a dataframe, column name of labels, and list of numbers of length (number of unique categories)\n",
        "  label_perms = permutations(pred_labels,5) #creating all possible permuations of labels \n",
        "  top_permutation = []\n",
        "  top_accuracy = 0\n",
        "  for perm in label_perms:\n",
        "    true_vals = []\n",
        "    for val in df[true_val_col].values:\n",
        "      if val == 'business':\n",
        "        true_vals.append(perm[0])\n",
        "      elif val == 'entertainment':\n",
        "        true_vals.append(perm[1])\n",
        "      elif val == 'sport':\n",
        "        true_vals.append(perm[2]) \n",
        "      elif val == 'tech':\n",
        "        true_vals.append(perm[3]) \n",
        "      else:\n",
        "        true_vals.append(perm[4])\n",
        "    accuracy = metrics.accuracy_score(true_vals, predicted_topics)\n",
        "    if accuracy >  top_accuracy:\n",
        "      top_accuracy = accuracy\n",
        "      top_permutation = perm \n",
        "  return top_permutation, top_accuracy\n",
        "labels, accuracy = find_max_accuracy(train, 'Category', [0,1,2,3,4]) #extracting labels that give the model the highest accuracy"
      ],
      "metadata": {
        "id": "0IBzOcuc-s1N"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Correct labels: {labels}\\nModel Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "KHI90tV4Ckqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf5c0dd-b1eb-4efa-ff7d-bb93972d5f03"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct labels: (4, 3, 0, 2, 1)\n",
            "Model Accuracy: 0.9395973154362416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n"
      ],
      "metadata": {
        "id": "G6sE191VAO5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1qejcZKFAO2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission"
      ],
      "metadata": {
        "id": "vHz8sf8hAM_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessing(test, 'Text') #preprocessing text for model\n",
        "test_vec = TfidfVectorizer().fit_transform(test['Text'].values) #vectorizing for model\n",
        "nmf = NMF(n_components=5, \n",
        "                init='nndsvda', \n",
        "                solver = 'mu',\n",
        "                beta_loss = 'kullback-leibler',\n",
        "                l1_ratio = 0.5,\n",
        "                random_state = 47)\n",
        "transformed_test = nmf.fit_transform(test_vec)"
      ],
      "metadata": {
        "id": "7y3oD1haAWMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5900a96a-74b1-435f-c96c-1a482cadcd76"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_sub_pred = []\n",
        "pred_test = [np.argsort(each)[len(each)-1] for each in transformed_test] #create list by grabbing indices of value with highest probability\n",
        "for val in pred_test: # coverting numeric labels into categorical labels for submission \n",
        "  if val == labels[0] :\n",
        "      final_sub_pred.append('business')\n",
        "  elif val == labels[1]:\n",
        "    final_sub_pred.append('entertainment')\n",
        "  elif val == labels[2]:\n",
        "    final_sub_pred.append('sport') \n",
        "  elif val == labels[3]:\n",
        "    final_sub_pred.append('tech') \n",
        "  else:\n",
        "    final_sub_pred.append('politics')"
      ],
      "metadata": {
        "id": "db-2usg3IloI"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(list(zip(test['ArticleId'], final_sub_pred)),\n",
        "               columns =['ArticleId', 'Category'])\n",
        "submission.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "zeW8DMe-_CrV",
        "outputId": "334b2eff-c49d-423d-b2a6-3f4a400ebcbd"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ArticleId       Category\n",
              "0        1018          sport\n",
              "1        1319  entertainment\n",
              "2        1138          sport\n",
              "3         459           tech\n",
              "4        1020          sport\n",
              "5          51          sport\n",
              "6        2025       politics\n",
              "7        1479       politics\n",
              "8          27       business\n",
              "9         397           tech\n",
              "10       1644           tech\n",
              "11        263  entertainment\n",
              "12        765       politics\n",
              "13       2134  entertainment\n",
              "14        297       business\n",
              "15       1712          sport\n",
              "16       1631       politics\n",
              "17        942  entertainment\n",
              "18       1549       business\n",
              "19        516       politics"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34820eb7-05d0-428b-888e-abbb269e5b52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1018</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1319</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1138</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>459</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1020</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>51</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1479</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>27</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>397</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1644</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>263</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>765</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2134</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>297</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1712</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1631</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>942</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1549</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>516</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34820eb7-05d0-428b-888e-abbb269e5b52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34820eb7-05d0-428b-888e-abbb269e5b52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34820eb7-05d0-428b-888e-abbb269e5b52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('News_NMF_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "_Swh-K4Q_J34"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "c1KuQT2IAUwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are major issues with using Non-negative Matrix Factorization. The model generalized horribly to new data. It achieved an accuracy of .42857 on the submission (test data). The supervised models in the other notebook performed much better. In the future I could run many iterations to tune hyperparamters for a pipeline consisting of the preprocessor, vectorizer, and model. This would likely be done through a gridsearch utilizing accuracy to choose the best hyperparamters. However, the runtime would be terribly inefficent so I decided not to do this."
      ],
      "metadata": {
        "id": "vA2E8W56NbQi"
      }
    }
  ]
}